{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/capitanio/linguaggio-naturale/blob/master/Linguaggio naturale B.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elaborazione del linguaggio naturale\n",
    "\n",
    "## Sentiment analisys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "abbiamo due file di pareri positivi e negativi nella cartella corpus.\n",
    "Usiamo questi due file per addestrare la nostra AI a riconoscere i parei positivi e negativi.\n",
    "Abbiamo bisogno di tre procedure di servizio per elaborare i nostri dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(document):\n",
    "    return set(\n",
    "        word.lower() for word in nltk.word_tokenize(document)\n",
    "        if any(c.isalpha() for c in word)\n",
    "    )\n",
    "\n",
    "\n",
    "def load_data(directory):\n",
    "    result = []\n",
    "    for filename in [\"positives.txt\", \"negatives.txt\"]:\n",
    "        with open(os.path.join(directory, filename)) as f:\n",
    "            result.append([\n",
    "                extract_words(line)\n",
    "                for line in f.read().splitlines()\n",
    "            ])\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_features(documents, words, label):\n",
    "    features = []\n",
    "    for document in documents:\n",
    "        features.append(({\n",
    "            word: (word in document)\n",
    "            for word in words\n",
    "        }, label))\n",
    "    return features\n",
    "\n",
    "\n",
    "def classify(classifier, document, words):\n",
    "    document_words = extract_words(document)\n",
    "    features = {\n",
    "        word: (word in document_words)\n",
    "        for word in words\n",
    "    }\n",
    "    return classifier.prob_classify(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non è necessario comprendere il funzionamento delle 3 funzioni di servizio.\n",
    "Ciò che interessa è che adesso possiamo leggere i commenti già classificati e addestrare la nostra AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives, negatives = load_data(\"corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creaiamo un insieme di tutte le parole del nostro set di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = set()\n",
    "for document in positives:\n",
    "    words.update(document)\n",
    "for document in negatives:\n",
    "    words.update(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo la nostra AI con i commenti positivi e con quelli negativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "training.extend(generate_features(positives, words, \"Positive\"))\n",
    "training.extend(generate_features(negatives, words, \"Negative\"))\n",
    "classifier = nltk.NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso possiamo provare a classificare alcuni commenti con la nostra AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.4639\n",
      "Negative: 0.5361\n"
     ]
    }
   ],
   "source": [
    "s = \"prodotto di qualità scadente!\"\n",
    "result = (classify(classifier, s, words))\n",
    "for key in result.samples():\n",
    "    print(f\"{key}: {result.prob(key):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.1186\n",
      "Negative: 0.8814\n"
     ]
    }
   ],
   "source": [
    "s = \"pessimo prodotto di qualità scadente. Non lo ricomprerei!\"\n",
    "result = (classify(classifier, s, words))\n",
    "for key in result.samples():\n",
    "    print(f\"{key}: {result.prob(key):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.2877\n",
      "Negative: 0.7123\n"
     ]
    }
   ],
   "source": [
    "s = \"packaging discreto ma prodotto di scarsa qualità. Non lo ricomprerei!\"\n",
    "result = (classify(classifier, s, words))\n",
    "for key in result.samples():\n",
    "    print(f\"{key}: {result.prob(key):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27790848d2f697d033d515d6398d3508bf4a8733d68ef0aee9b2086a7f9df1cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
